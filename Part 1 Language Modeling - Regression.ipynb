{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2124baec-d62e-4bd8-b2bd-7aa8495491b3",
   "metadata": {},
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa20767-a7fa-4882-a0d1-bde0589e6200",
   "metadata": {},
   "source": [
    "##### Objective : The main purpose behind this lab is to get familiar with NLP language models using Sklearn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09e5a3-8380-4399-bbe7-0fb70465bf49",
   "metadata": {},
   "source": [
    "## Part 1: Language Modeling / Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e176e4bc-6256-4a5c-92b4-4e424b619a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a168f5cc-a58c-4a07-a4a1-687fa2c404ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dbbrandt/short_answer_granding_capstone_project/master/data/sag/answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbf8d48-b4e7-44f4-b5bb-3207199d27ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             answer  score  correct\n",
       "0  1.1  High risk problems are address in the prototyp...    3.5      0.0\n",
       "1  1.1  To simulate portions of the desired final prod...    5.0      1.0\n",
       "2  1.1  A prototype program simulates the behaviors of...    4.0      1.0\n",
       "3  1.1  Defined in the Specification phase a prototype...    5.0      1.0\n",
       "4  1.1  It is used to let the users have a first idea ...    3.0      0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c334333-b065-4efb-bf4e-45b8243ea03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2442 entries, 0 to 2441\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       2442 non-null   float64\n",
      " 1   answer   2442 non-null   object \n",
      " 2   score    2442 non-null   float64\n",
      " 3   correct  2442 non-null   float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 76.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d32cc70-f4c1-4df1-ae96-5fbf82c1333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "answer     0\n",
       "score      0\n",
       "correct    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c885c2-3c50-408b-81b3-210a3adbe229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575d4135-9929-4236-937d-9c1d5c565101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35876906-9fed-4e64-bd28-82bcb0f3c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Non-String\n",
    "def filter_non_string(df, column):\n",
    "    \"\"\"\n",
    "    Filter out rows with non-string values in the specified column.\n",
    "    Convert non-string values to strings.\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[column])\n",
    "    df[column] = df[column].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d57a51-7013-4a4c-825c-3f4d07cfe8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert In LowerCase\n",
    "def normalize_text(text):\n",
    "    \"\"\"Convert text to lowercase to ensure consistency across the corpus.\"\"\"\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38fe350d-a35c-4766-8570-50867ec5fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML Tags\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from text.\"\"\"\n",
    "    return re.sub(r'<.*?>', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82691cf-2895-45ad-8978-2d42951d1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URL Or HyperLink\n",
    "def remove_urls(text):\n",
    "    \"\"\"Remove URLs or hyperlinks from the text.\"\"\"\n",
    "    return re.sub(r'http\\S+|www\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9147a8-bc25-414b-b65f-b853e1f0854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Numeric Digit\n",
    "def remove_numbers(text):\n",
    "    \"\"\"Exclude numerical digits from the text.\"\"\"\n",
    "    return re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e44c072-f151-4fa1-ab3a-29cd0005d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation marks from the text.\"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdb7c0d7-c0dc-4b5a-94f9-3b27bb29c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lemmatization\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1ecc0a7-15c9-4df0-9c5c-bef6531884a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Text In Token\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Split the text into individual words or tokens.\"\"\"\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c854064-92b0-4ad6-8cd2-c842e0e689b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate Stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Eliminate common stopwords from the tokenized text.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb5c5f4-452e-43da-98ca-e549b673df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    df = filter_non_string(df, 'answer')\n",
    "    df['answer'] = df['answer'].apply(normalize_text)\n",
    "    df['answer'] = df['answer'].apply(remove_html_tags)\n",
    "    df['answer'] = df['answer'].apply(remove_urls)\n",
    "    df['answer'] = df['answer'].apply(remove_numbers)\n",
    "    df['answer'] = df['answer'].apply(remove_punctuation)\n",
    "    df['answer'] = df['answer'].apply(lemmatize_text)\n",
    "    df['answer'] = df['answer'].apply(tokenize_text)\n",
    "    df['answer'] = df['answer'].apply(remove_stopwords)\n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df_processed = preprocess_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920c02eb-e63e-4439-a764-78ca9e4623b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>[high, risk, problem, address, prototype, prog...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>[simulate, portion, desired, final, product, q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>[prototype, program, simulates, behavior, port...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>[defined, specification, phase, prototype, sti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>[used, let, user, first, idea, completed, prog...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             answer  score  correct\n",
       "0  1.1  [high, risk, problem, address, prototype, prog...    3.5      0.0\n",
       "1  1.1  [simulate, portion, desired, final, product, q...    5.0      1.0\n",
       "2  1.1  [prototype, program, simulates, behavior, port...    4.0      1.0\n",
       "3  1.1  [defined, specification, phase, prototype, sti...    5.0      1.0\n",
       "4  1.1  [used, let, user, first, idea, completed, prog...    3.0      0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0ea10b-9002-4e21-ace4-cced1ce37b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# For Skip-gram, set sg=1\n",
    "model = Word2Vec(sentences=df_processed['answer'], vector_size=100, window=5, min_count=1, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acd1f760-b28c-4142-841b-df2abdd4c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # Remove out-of-vocabulary words and get word vectors\n",
    "    doc_vectors = [word2vec_model.wv[word] for word in doc if word in word2vec_model.wv]\n",
    "\n",
    "    # Calculate the mean vector\n",
    "    if doc_vectors:\n",
    "        return np.mean(doc_vectors, axis=0)\n",
    "    else:\n",
    "        # Handle cases where no valid word vectors are found\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Assuming 'df_processed' contains your preprocessed data\n",
    "df_processed['vector'] = df_processed['answer'].apply(lambda x: document_vector(model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a37bdcaf-44f1-41a1-b6bf-f12be013ca7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.0014370893, 0.075638264, -0.048081852, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.018521447, 0.06257434, -0.052992724, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.009561417, 0.06691981, -0.0512529, 0.04687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.0072238813, 0.064176045, -0.050638255, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.02020907, 0.05126546, -0.034119498, 0.0329...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  score  correct                                             vector\n",
       "0  1.1    3.5      0.0  [-0.0014370893, 0.075638264, -0.048081852, 0.0...\n",
       "1  1.1    5.0      1.0  [-0.018521447, 0.06257434, -0.052992724, 0.028...\n",
       "2  1.1    4.0      1.0  [-0.009561417, 0.06691981, -0.0512529, 0.04687...\n",
       "3  1.1    5.0      1.0  [-0.0072238813, 0.064176045, -0.050638255, 0.0...\n",
       "4  1.1    3.0      0.0  [-0.02020907, 0.05126546, -0.034119498, 0.0329..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'answer' column\n",
    "df_processed.drop(columns=['answer'], inplace=True)\n",
    "\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c61054d6-93e5-4828-b7cc-c18fd473e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df_processed['vector'].tolist()\n",
    "y = df_processed['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d61682f-f6b1-4ddd-af1e-d06704884f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c203442-5d91-4ea0-aa61-caee22c0f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "svr_model = SVR()\n",
    "lr_model = LinearRegression()\n",
    "dt_model = DecisionTreeRegressor()\n",
    "rf_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dbfd3a1-71e1-4617-a45c-c8fdca4b56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Best Params: {'C': 10, 'kernel': 'rbf'}\n",
      "SVR Best CV Score: 1.172725333467206\n",
      "Linear Regression Best Params: {}\n",
      "Linear Regression Best CV Score: 1.006498434110711\n",
      "Decision Tree Best Params: {'max_depth': 10, 'min_samples_split': 20}\n",
      "Decision Tree Best CV Score: 1.2911495431951052\n",
      "Random Forest Best Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Best CV Score: 0.9531643492829762\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grids for each model\n",
    "param_grid_svr = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf']}\n",
    "param_grid_lr = {}  # LinearRegression does not have hyperparameters to tune\n",
    "param_grid_dt = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 10, 20]}\n",
    "param_grid_rf = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 10, 20]}\n",
    "\n",
    "# Initialize GridSearchCV for each model\n",
    "grid_search_svr = GridSearchCV(svr_model, param_grid_svr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_lr = GridSearchCV(lr_model, param_grid_lr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the models\n",
    "grid_search_svr.fit(X_train, y_train)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and scores\n",
    "best_params_svr = grid_search_svr.best_params_\n",
    "best_score_svr = -grid_search_svr.best_score_\n",
    "\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_score_lr = -grid_search_lr.best_score_\n",
    "\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "best_score_dt = -grid_search_dt.best_score_\n",
    "\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_score_rf = -grid_search_rf.best_score_\n",
    "\n",
    "# Print results\n",
    "print(\"SVR Best Params:\", best_params_svr)\n",
    "print(\"SVR Best CV Score:\", best_score_svr)\n",
    "\n",
    "print(\"Linear Regression Best Params:\", best_params_lr)\n",
    "print(\"Linear Regression Best CV Score:\", best_score_lr)\n",
    "\n",
    "print(\"Decision Tree Best Params:\", best_params_dt)\n",
    "print(\"Decision Tree Best CV Score:\", best_score_dt)\n",
    "\n",
    "print(\"Random Forest Best Params:\", best_params_rf)\n",
    "print(\"Random Forest Best CV Score:\", best_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7debea-07f7-4ceb-b564-72a380bd2a0d",
   "metadata": {},
   "source": [
    "Now, let’s discuss the interpretation of these results:\r\n",
    "\r\n",
    "- The **Random Forest** model achieved the lowest MSE, indicating better performance compared to the other models.\r\n",
    "- The **SVR** model with an RBF kernel also performed reasonably well, but its MSE was slightly higher than that of Random Forest.\r\n",
    "- **Linear Regression** had the highest MSE, suggesting that it may not be the best choice for this dataset.\r\n",
    "- The **Decision Tree** model fell in between, with moderate performnce.\r\n",
    "ance.ance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
