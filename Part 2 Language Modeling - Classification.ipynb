{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a117af34-6487-4f97-a029-ef19f3c6cca7",
   "metadata": {},
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f3709-bfd7-4563-8e1d-c86bd3df8bbe",
   "metadata": {},
   "source": [
    "##### Objective : The main purpose behind this lab is to get familiar with NLP language models using Sklearn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022aee8-0762-4526-84d4-cb4cef1e2cec",
   "metadata": {},
   "source": [
    "## Part 2: Language Modeling / Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0137e46-1bb1-430f-809a-e01b43040043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506610e3-54f9-4d23-aadb-697f5358faa2",
   "metadata": {},
   "source": [
    "Dataset used : https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "536cdd98-3509-437e-ba40-03a84662f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train_dataset = pd.read_csv('twitter_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f96b4753-2003-41d3-8a62-e9280e644334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "      <th>Borderlands</th>\n",
       "      <th>Positive</th>\n",
       "      <th>im getting on borderlands and i will murder you all ,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2401  Borderlands  Positive  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "  im getting on borderlands and i will murder you all ,  \n",
       "0  I am coming to the borders and I will kill you...     \n",
       "1  im getting on borderlands and i will kill you ...     \n",
       "2  im coming on borderlands and i will murder you...     \n",
       "3  im getting on borderlands 2 and i will murder ...     \n",
       "4  im getting into borderlands and i can murder y...     "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90503b60-834b-4f4e-919a-eab375c52203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74681 entries, 0 to 74680\n",
      "Data columns (total 4 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype \n",
      "---  ------                                                 --------------  ----- \n",
      " 0   2401                                                   74681 non-null  int64 \n",
      " 1   Borderlands                                            74681 non-null  object\n",
      " 2   Positive                                               74681 non-null  object\n",
      " 3   im getting on borderlands and i will murder you all ,  73995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b308866d-25fd-4405-b23a-3677b86f5b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74681.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6432.640149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3740.423819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2401\n",
       "count  74681.000000\n",
       "mean    6432.640149\n",
       "std     3740.423819\n",
       "min        1.000000\n",
       "25%     3195.000000\n",
       "50%     6422.000000\n",
       "75%     9601.000000\n",
       "max    13200.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2db35b1e-d263-465f-8c9f-8d5faedddc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.columns = ['Tweet ID', 'Entity','Sentiment','Tweet content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "463177fe-8a00-44b5-b4d4-237ce7976b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID       Entity Sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  I am coming to the borders and I will kill you...  \n",
       "1  im getting on borderlands and i will kill you ...  \n",
       "2  im coming on borderlands and i will murder you...  \n",
       "3  im getting on borderlands 2 and i will murder ...  \n",
       "4  im getting into borderlands and i can murder y...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8ee2d6f-53d1-4d2f-b656-be8ff0ae2aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet ID           0\n",
       "Entity             0\n",
       "Sentiment          0\n",
       "Tweet content    686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4d07fd4-ed04-43b4-8e29-d939bc0a86d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet ID         0\n",
       "Entity           0\n",
       "Sentiment        0\n",
       "Tweet content    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dropna(inplace=True)\n",
    "train_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0f67d57-78bc-4feb-97fc-58c60ec60481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "637275b3-386d-47ed-8f6a-62956d33933f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.drop_duplicates(inplace=True)\n",
    "train_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c3346a1-1947-4e0e-a3d5-5600414a9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Non-String\n",
    "def filter_non_string(df, column):\n",
    "    \"\"\"\n",
    "    Filter out rows with non-string values in the specified column.\n",
    "    Convert non-string values to strings.\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[column])\n",
    "    df[column] = df[column].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95b62ee6-dd8a-423e-b148-b2c3c1278f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert In LowerCase\n",
    "def normalize_text(text):\n",
    "    \"\"\"Convert text to lowercase to ensure consistency across the corpus.\"\"\"\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a447fed2-ab02-42b4-a2bc-66b8befa81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML Tags\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from text.\"\"\"\n",
    "    return re.sub(r'<.*?>', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c99ca0a-31f9-4f7b-9b00-a85adccebb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URL Or HyperLink\n",
    "def remove_urls(text):\n",
    "    \"\"\"Remove URLs or hyperlinks from the text.\"\"\"\n",
    "    return re.sub(r'http\\S+|www\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "421d8d28-4c29-43a6-94c5-fac7449cd5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Numeric Digit\n",
    "def remove_numbers(text):\n",
    "    \"\"\"Exclude numerical digits from the text.\"\"\"\n",
    "    return re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac4b591b-621a-4f69-a69c-648920250aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation marks from the text.\"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a71fb68-038b-4e74-b4e6-71991a925123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Stemming\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "231a96bd-de01-48c2-a069-a222d2a25e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Text In Token\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Split the text into individual words or tokens.\"\"\"\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb4acdfc-72fa-4139-bbc9-100a6823a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate Stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Eliminate common stopwords from the tokenized text.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e6ad8b1-bb0d-420d-a87d-3190ed1b5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Emojis\n",
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"Remove emojis from the text.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   u\"\\U0001f926-\\U0001f937\"\n",
    "                                   u\"\\U00010000-\\U0010ffff\"\n",
    "                                   u\"\\u2640-\\u2642\"\n",
    "                                   u\"\\u2600-\\u2B55\"\n",
    "                                   u\"\\u200d\"\n",
    "                                   u\"\\u23cf\"\n",
    "                                   u\"\\u23e9\"\n",
    "                                   u\"\\u231a\"\n",
    "                                   u\"\\ufe0f\"  # dingbats\n",
    "                                   u\"\\u3030\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6bc53b5c-05f1-4afb-a170-417a44eaeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    df = filter_non_string(df, 'Tweet content')\n",
    "    df['Tweet content'] = df['Tweet content'].apply(normalize_text)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(remove_html_tags)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(remove_urls)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(remove_numbers)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(remove_punctuation)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(stem_text)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(tokenize_text)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(remove_stopwords)\n",
    "    df['Tweet content'] = df['Tweet content'].apply(remove_emojis)\n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "data_processed = preprocess_text(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "460acba9-47af-416a-8415-b5bd5f792ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[come, border, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[im, get, borderland, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[im, come, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[im, get, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[im, get, borderland, murder]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID       Entity Sentiment                   Tweet content\n",
       "0      2401  Borderlands  Positive            [come, border, kill]\n",
       "1      2401  Borderlands  Positive     [im, get, borderland, kill]\n",
       "2      2401  Borderlands  Positive  [im, come, borderland, murder]\n",
       "3      2401  Borderlands  Positive   [im, get, borderland, murder]\n",
       "4      2401  Borderlands  Positive   [im, get, borderland, murder]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77691f41-420f-44fc-b78e-b8dd47c4af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the 'Entity' feature\n",
    "data_processed['Entity'] = le.fit_transform(data_processed['Entity'])\n",
    "\n",
    "# Encode the 'Sentiment' target variable\n",
    "data_processed['Sentiment'] = le.fit_transform(data_processed['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c309a798-1564-4514-bdb4-b4786522918a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[come, border, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[im, get, borderland, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[im, come, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[im, get, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[im, get, borderland, murder]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID  Entity  Sentiment                   Tweet content\n",
       "0      2401       4          3            [come, border, kill]\n",
       "1      2401       4          3     [im, get, borderland, kill]\n",
       "2      2401       4          3  [im, come, borderland, murder]\n",
       "3      2401       4          3   [im, get, borderland, murder]\n",
       "4      2401       4          3   [im, get, borderland, murder]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4966733-7592-4bf5-a2f7-4eb111901ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 71655 entries, 0 to 74680\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet ID       71655 non-null  int64 \n",
      " 1   Entity         71655 non-null  int32 \n",
      " 2   Sentiment      71655 non-null  int32 \n",
      " 3   Tweet content  71655 non-null  object\n",
      "dtypes: int32(2), int64(1), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43217e4c-14f7-4bb8-a460-dbd8273cc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CBOW, set sg=0\n",
    "model = Word2Vec(sentences=data_processed['Tweet content'], vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # Remove out-of-vocabulary words and get word vectors\n",
    "    doc_vectors = [word2vec_model.wv[word] for word in doc if word in word2vec_model.wv]\n",
    "\n",
    "    # Calculate the mean vector\n",
    "    if doc_vectors:\n",
    "        return np.mean(doc_vectors, axis=0)\n",
    "    else:\n",
    "        # Handle cases where no valid word vectors are found\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Assuming 'df_processed' contains your preprocessed data\n",
    "data_processed['vector'] = data_processed['Tweet content'].apply(lambda x: document_vector(model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2716803e-7099-4eb1-8b50-364f87fd11f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.4013606, 0.28093326, 0.09325939, -0.227747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.26614723, -0.3103593, 0.64801896, -1.22333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.44388476, -0.6167488, 0.29682255, -0.98067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.23910753, -0.5785432, 0.56877416, -1.14945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.23910753, -0.5785432, 0.56877416, -1.14945...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID  Entity  Sentiment  \\\n",
       "0      2401       4          3   \n",
       "1      2401       4          3   \n",
       "2      2401       4          3   \n",
       "3      2401       4          3   \n",
       "4      2401       4          3   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.4013606, 0.28093326, 0.09325939, -0.227747...  \n",
       "1  [-0.26614723, -0.3103593, 0.64801896, -1.22333...  \n",
       "2  [-0.44388476, -0.6167488, 0.29682255, -0.98067...  \n",
       "3  [-0.23910753, -0.5785432, 0.56877416, -1.14945...  \n",
       "4  [-0.23910753, -0.5785432, 0.56877416, -1.14945...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'Tweet content' column\n",
    "data_processed.drop(columns=['Tweet content'], inplace=True)\n",
    "\n",
    "data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5af2616b-ab17-42cd-b64f-36d1c9a6d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = np.vstack(data_processed['vector'].values)\n",
    "y = data_processed['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e1193ca-e433-4018-b1fe-73eb48798152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1273164-2e85-406b-b9f5-ea1cdaa7189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.541064824506315\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.19      0.27      2455\n",
      "           1       0.59      0.70      0.64      4433\n",
      "           2       0.49      0.53      0.50      3532\n",
      "           3       0.54      0.60      0.57      3911\n",
      "\n",
      "    accuracy                           0.54     14331\n",
      "   macro avg       0.52      0.50      0.50     14331\n",
      "weighted avg       0.53      0.54      0.52     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with only the Random Forest Classifier\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Generate the classification report\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_lr}\")\n",
    "print(f\"Classification Report:\\n{report_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c035506-7bdd-43a4-9dce-0ca0352cbdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7383992743004675\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65      2455\n",
      "           1       0.75      0.82      0.78      4433\n",
      "           2       0.74      0.70      0.72      3532\n",
      "           3       0.70      0.80      0.75      3911\n",
      "\n",
      "    accuracy                           0.74     14331\n",
      "   macro avg       0.75      0.72      0.73     14331\n",
      "weighted avg       0.74      0.74      0.73     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with only the Random Forest Classifier\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Generate the classification report\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"Classification Report:\\n{report_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc9bfba9-e927-4c69-9bdf-ab3bb819d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5034540506594096\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.18      0.24      2455\n",
      "           1       0.56      0.68      0.61      4433\n",
      "           2       0.47      0.41      0.44      3532\n",
      "           3       0.49      0.59      0.53      3911\n",
      "\n",
      "    accuracy                           0.50     14331\n",
      "   macro avg       0.48      0.46      0.46     14331\n",
      "weighted avg       0.49      0.50      0.49     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with only the Random Forest Classifier\n",
    "model_ab = AdaBoostClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_ab.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_ab = model_ab.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_ab = accuracy_score(y_test, y_pred_ab)\n",
    "\n",
    "# Generate the classification report\n",
    "report_ab = classification_report(y_test, y_pred_ab)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_ab}\")\n",
    "print(f\"Classification Report:\\n{report_ab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b0945-f95c-40fe-8e92-109c07c1d79e",
   "metadata": {},
   "source": [
    "We performed the embedding on our data using Word2Vec using the CBOW approach, and the RandomForest was the best model so far, we're going to try now another approach of embedding using TF-IDF on the RandomForest model and compare it with the performance of CBOW Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "220b24cc-6562-44de-a40b-9fe2510b100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9064964063917382\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.96      0.84      0.90      2455\n",
      "    Negative       0.93      0.93      0.93      4433\n",
      "     Neutral       0.92      0.88      0.90      3532\n",
      "    Positive       0.85      0.94      0.89      3911\n",
      "\n",
      "    accuracy                           0.91     14331\n",
      "   macro avg       0.91      0.90      0.90     14331\n",
      "weighted avg       0.91      0.91      0.91     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocess our data\n",
    "data_processed = preprocess_text(train_dataset)\n",
    "\n",
    "# Join the words in the 'Tweet content' column\n",
    "data_processed['Tweet content'] = data_processed['Tweet content'].apply(' '.join)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data_processed['Tweet content']\n",
    "y = data_processed['Sentiment']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with TF-IDF Vectorizer and Random Forest Classifier\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Generate the classification report\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"Classification Report:\\n{report_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283e80c-2abc-4b85-ae01-8a69dad34eef",
   "metadata": {},
   "source": [
    "In our classification task, we experimented with two different models: TF-IDF with Word Embedding and CBOW. The TF-IDF model achieved an impressive accuracy of approximately 90.65%, outperforming CBOW, which had an accuracy of around 73.84%. The precision, recall, and F1-score were consistently high for the TF-IDF model across all classes (Irrelevant, Negative, Neutral, and Positive). In contrast, CBOW struggled with class 0 (low recall) and class 2 (lower precision and recall). Further exploration and optimization may be needed to enhance CBOW’s performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
